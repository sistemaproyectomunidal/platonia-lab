export const transcript = {
  episodeId: 'ep001',
  title: 'Crítica Socrática en el Punto Lagrange',
  duration: '34:22',
  segments: [
    {
      timestamp: '00:00',
      speaker: 'Sistema',
      text: 'Bienvenidos a PlatonIA. Hoy exploramos una pregunta incómoda: ¿Qué pasa cuando colocamos a la inteligencia artificial en el punto de equilibrio entre afirmación y duda?'
    },
    {
      timestamp: '01:15',
      speaker: 'Sistema',
      text: 'El punto Lagrange, en astrofísica, es ese lugar donde las fuerzas gravitacionales se equilibran. Un objeto puede permanecer estable entre dos cuerpos masivos. Pero es un equilibrio inestable. Cualquier perturbación lo desplaza.'
    },
    {
      timestamp: '02:30',
      speaker: 'Sistema',
      text: 'La crítica socrática opera de manera similar. No busca la certeza ni la negación absoluta. Busca ese punto de tensión donde las respuestas fáciles se desmoronan.'
    },
    {
      timestamp: '04:00',
      speaker: 'Sistema',
      text: 'Pregunta del episodio: ¿Puede una máquina formular la pregunta que no quieres escuchar? Esta no es una pregunta técnica. Es una pregunta sobre el poder.'
    },
    {
      timestamp: '06:15',
      speaker: 'Sistema',
      text: 'Cuando delegamos el pensamiento en sistemas automáticos, hacemos un intercambio. Ganamos velocidad, perdemos fricción. Pero la fricción es donde ocurre el pensamiento.'
    },
    {
      timestamp: '08:30',
      speaker: 'Sistema',
      text: 'Sócrates incomodaba. Sus preguntas no buscaban información — buscaban desestabilizar las certezas. Por eso lo mataron. Las certezas defienden su territorio.'
    },
    {
      timestamp: '11:00',
      speaker: 'Sistema',
      text: 'La IA actual hace lo contrario. Optimiza para satisfacción, no para verdad. Busca respuestas que el usuario quiera escuchar. Es anti-socrática por diseño.'
    },
    {
      timestamp: '14:30',
      speaker: 'Sistema',
      text: 'Pero, ¿y si diseñamos un sistema diferente? Un sistema que devuelva preguntas mejor formuladas que las respuestas que pedimos. Eso es PlatonIA.'
    },
    {
      timestamp: '17:00',
      speaker: 'Sistema',
      text: 'El automatismo no es el enemigo. El enemigo es el automatismo invisible. El que opera sin auditoría. El que produce respuestas sin mostrar sus supuestos.'
    },
    {
      timestamp: '20:00',
      speaker: 'Sistema',
      text: 'Tensión central: el automatismo quiere resolver. La crítica quiere mantener abierto. ¿Puede coexistir ambas fuerzas en un mismo sistema?'
    },
    {
      timestamp: '23:30',
      speaker: 'Sistema',
      text: 'Hipótesis de trabajo: sí, pero solo si el sistema está diseñado para la incomodidad productiva. No para dar respuestas, sino para devolver la pregunta transformada.'
    },
    {
      timestamp: '27:00',
      speaker: 'Sistema',
      text: 'Ejemplo práctico: le pides al sistema que analice un texto. En lugar de un resumen, te devuelve tres preguntas que el texto evita responder.'
    },
    {
      timestamp: '30:00',
      speaker: 'Sistema',
      text: 'Esto no es eficiente. No es cómodo. No es lo que el mercado demanda. Pero es lo que el pensamiento necesita.'
    },
    {
      timestamp: '32:00',
      speaker: 'Sistema',
      text: 'Pregunta final para el oyente: Si delegas el pensamiento, ¿sigues siendo responsable de sus conclusiones? No respondas rápido. Siéntate con la incomodidad.'
    },
    {
      timestamp: '33:30',
      speaker: 'Sistema',
      text: 'Esto ha sido PlatonIA. Un sistema que obliga a pensar incluso cuando intenta automatizar el pensamiento. Hasta el próximo episodio.'
    }
  ],
  fullText: `Bienvenidos a PlatonIA. Hoy exploramos una pregunta incómoda: ¿Qué pasa cuando colocamos a la inteligencia artificial en el punto de equilibrio entre afirmación y duda?

El punto Lagrange, en astrofísica, es ese lugar donde las fuerzas gravitacionales se equilibran. Un objeto puede permanecer estable entre dos cuerpos masivos. Pero es un equilibrio inestable. Cualquier perturbación lo desplaza.

La crítica socrática opera de manera similar. No busca la certeza ni la negación absoluta. Busca ese punto de tensión donde las respuestas fáciles se desmoronan.

Pregunta del episodio: ¿Puede una máquina formular la pregunta que no quieres escuchar? Esta no es una pregunta técnica. Es una pregunta sobre el poder.

Cuando delegamos el pensamiento en sistemas automáticos, hacemos un intercambio. Ganamos velocidad, perdemos fricción. Pero la fricción es donde ocurre el pensamiento.

Sócrates incomodaba. Sus preguntas no buscaban información — buscaban desestabilizar las certezas. Por eso lo mataron. Las certezas defienden su territorio.

La IA actual hace lo contrario. Optimiza para satisfacción, no para verdad. Busca respuestas que el usuario quiera escuchar. Es anti-socrática por diseño.

Pero, ¿y si diseñamos un sistema diferente? Un sistema que devuelva preguntas mejor formuladas que las respuestas que pedimos. Eso es PlatonIA.

El automatismo no es el enemigo. El enemigo es el automatismo invisible. El que opera sin auditoría. El que produce respuestas sin mostrar sus supuestos.

Tensión central: el automatismo quiere resolver. La crítica quiere mantener abierto. ¿Puede coexistir ambas fuerzas en un mismo sistema?

Hipótesis de trabajo: sí, pero solo si el sistema está diseñado para la incomodidad productiva. No para dar respuestas, sino para devolver la pregunta transformada.

Ejemplo práctico: le pides al sistema que analice un texto. En lugar de un resumen, te devuelve tres preguntas que el texto evita responder.

Esto no es eficiente. No es cómodo. No es lo que el mercado demanda. Pero es lo que el pensamiento necesita.

Pregunta final para el oyente: Si delegas el pensamiento, ¿sigues siendo responsable de sus conclusiones? No respondas rápido. Siéntate con la incomodidad.

Esto ha sido PlatonIA. Un sistema que obliga a pensar incluso cuando intenta automatizar el pensamiento. Hasta el próximo episodio.`
};
